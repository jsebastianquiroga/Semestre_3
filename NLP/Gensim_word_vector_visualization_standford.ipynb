{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsebastianquiroga/analitica_ia_puj/blob/main/NLP/Gensim_word_vector_visualization_standford.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WORD 2 VEC Y GENSIM\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Word2Vec es un algoritmo de procesamiento del lenguaje natural (NLP) que utiliza redes neuronales profundas para aprender representaciones vectoriales de palabras a partir de grandes conjuntos de datos de texto. El objetivo es capturar la semántica de las palabras y la relación entre ellas en un espacio vectorial de baja dimensión.\n",
        "\n",
        "Por otro lado, Gensim es una biblioteca de NLP de código abierto que incluye herramientas para la creación de modelos de Word2Vec y también proporciona una herramienta de visualización de vectores de palabras. La visualización de vectores de palabras es una técnica que permite visualizar en un gráfico de dos o tres dimensiones cómo se relacionan las palabras entre sí en función de la proximidad semántica en un espacio vectorial. Esta visualización es muy útil para comprender cómo se relacionan las palabras en un conjunto de datos de texto y para identificar patrones y tendencias en el uso del lenguaje."
      ],
      "metadata": {
        "id": "BH_ooGo7nFNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "_kVs6McZnER2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "utiliza la biblioteca gensim para cargar un modelo pre-entrenado de vectores de palabras denominado \"glove-wiki-gigaword-100\". Este modelo contiene vectores de palabras que fueron entrenados en un corpus de texto grande utilizando el algoritmo de GloVe (Global Vectors), que es una técnica de aprendizaje no supervisado para representar palabras en un espacio vectorial de varias dimensiones.\n",
        "\n",
        "Al cargar este modelo, podemos acceder a los vectores de palabras pre-entrenados para una gran cantidad de palabras en inglés. Estos vectores de palabras pueden ser útiles para una variedad de tareas de procesamiento de lenguaje natural, como clasificación de texto, agrupamiento de texto, búsqueda de similitud de documentos y más."
      ],
      "metadata": {
        "id": "IXQBzZR1oh38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "id": "TpXAZ_AgoEYG",
        "outputId": "a9127522-8fd2-4b65-b964-574cc7aa3a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Representacion vectorial de la palabra \"bread\": ')\n",
        "print(model['bread'])\n",
        "print('---------------------------------------------------------------------')\n",
        "print('Representacion vectorial de la palabra \"croissant\": ')\n",
        "print(model['croissant'])\n"
      ],
      "metadata": {
        "id": "KVlGhLcnoppU",
        "outputId": "c5b1bf79-ad6f-4520-ac49-bb76d826d4d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Representacion vectorial de la palabra \"bread\": \n",
            "[-0.66146    0.94335   -0.72214    0.17403   -0.42524    0.36303\n",
            "  1.0135    -0.14802    0.25817   -0.20326   -0.64338    0.16632\n",
            "  0.61518    1.397     -0.094506   0.0041843 -0.18976   -0.55421\n",
            " -0.39371   -0.22501   -0.34643    0.32076    0.34395   -0.7034\n",
            "  0.23932    0.69951   -0.16461   -0.31819   -0.34034   -0.44906\n",
            " -0.069667   0.35348    0.17498   -0.95057   -0.2209     1.0647\n",
            "  0.23231    0.32569    0.47662   -1.1206     0.28168   -0.75172\n",
            " -0.54654   -0.66337    0.34804   -0.69058   -0.77092   -0.40167\n",
            " -0.069351  -0.049238  -0.39351    0.16735   -0.14512    1.0083\n",
            " -1.0608    -0.87314   -0.29339    0.68278    0.61634   -0.088844\n",
            "  0.88094    0.099809  -0.27161   -0.58026    0.50364   -0.93814\n",
            "  0.67576   -0.43124   -0.10517   -1.2404    -0.74353    0.28637\n",
            "  0.29012    0.89377    0.67406    0.86422   -0.30693   -0.14718\n",
            "  0.078353   0.74013    0.32658   -0.052579  -1.1665     0.87079\n",
            " -0.69402   -0.75977   -0.37164   -0.11887    0.18551    0.041883\n",
            "  0.59352    0.30519   -0.54819   -0.29424   -1.4912    -1.6548\n",
            "  0.98982    0.27325    1.009      0.94544  ]\n",
            "---------------------------------------------------------------------\n",
            "Representacion vectorial de la palabra \"croissant\": \n",
            "[-0.25144    0.52157   -0.75452    0.28039   -0.31388    0.274\n",
            "  1.1971    -0.10519    0.82544   -0.33398   -0.21417    0.22216\n",
            "  0.14982    0.47384    0.41984    0.69397   -0.25999   -0.44414\n",
            "  0.58296   -0.30851   -0.076455   0.33468    0.28055   -0.99012\n",
            "  0.30349    0.39128    0.031526  -0.095395  -0.004745  -0.81347\n",
            "  0.27869   -0.1812     0.14632   -0.42186    0.13857    1.139\n",
            "  0.14925   -0.051459   0.37875   -0.2613     0.011081  -0.28881\n",
            " -0.38662   -0.3135    -0.1954     0.19248   -0.52995   -0.40674\n",
            " -0.25159    0.06272   -0.32724    0.28374   -0.2155    -0.061832\n",
            " -0.50134    0.0093959  0.30715    0.3873    -0.74554   -0.45947\n",
            "  0.40032   -0.1378    -0.26968   -0.3946    -0.64876   -0.47149\n",
            " -0.085536   0.092795  -0.034018  -0.61906    0.19123    0.20563\n",
            "  0.29056   -0.010908   0.15313    0.33144    0.33806    0.061708\n",
            "  0.20785    0.65348   -0.053222   0.18589    0.32647   -0.11923\n",
            "  0.42008   -0.26931    0.025489   0.0036535  0.1327    -0.22763\n",
            "  0.07564    0.55773    0.2978     0.28144    0.19775   -0.23582\n",
            "  0.65303    0.089897   0.35844    0.14304  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('MAs similares con \"usa\": ')\n",
        "\n",
        "model.most_similar('usa')"
      ],
      "metadata": {
        "id": "gxZbBOyostf7",
        "outputId": "5412fe7d-4cbf-490e-caa6-5e85634317c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAs similares con \"usa\": \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('canada', 0.6544384956359863),\n",
              " ('america', 0.645224392414093),\n",
              " ('u.s.a.', 0.6184033751487732),\n",
              " ('united', 0.6017189621925354),\n",
              " ('states', 0.5970699191093445),\n",
              " ('australia', 0.5838716626167297),\n",
              " ('world', 0.5590084195137024),\n",
              " ('2010', 0.5580702424049377),\n",
              " ('2012', 0.5504006743431091),\n",
              " ('davis', 0.5464468002319336)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('MAs similares con \"banana\": ')\n",
        "\n",
        "model.most_similar('banana')"
      ],
      "metadata": {
        "id": "DhO_9Mszo7_S",
        "outputId": "3ea15120-9163-4a74-f373-e6b60dffccca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAs similares con \"usa\": \n",
            "MAs similares con \"banana\": \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('coconut', 0.7097253203392029),\n",
              " ('mango', 0.7054824829101562),\n",
              " ('bananas', 0.6887733340263367),\n",
              " ('potato', 0.6629636287689209),\n",
              " ('pineapple', 0.6534532308578491),\n",
              " ('fruit', 0.6519854664802551),\n",
              " ('peanut', 0.6420575976371765),\n",
              " ('pecan', 0.6349173188209534),\n",
              " ('cashew', 0.6294420957565308),\n",
              " ('papaya', 0.6246591210365295)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Menos similares con \"banana\": ')\n",
        "\n",
        "model.most_similar(negative =  'banana')"
      ],
      "metadata": {
        "id": "DTa25u3sp9e0",
        "outputId": "a715f085-7df4-43d4-c186-0c92708c852d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menos similares con \"banana\": \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('shunichi', 0.49618104100227356),\n",
              " ('ieronymos', 0.4736502170562744),\n",
              " ('pengrowth', 0.4668096601963043),\n",
              " ('höss', 0.4636845588684082),\n",
              " ('damaskinos', 0.4617849290370941),\n",
              " ('yadin', 0.4617374837398529),\n",
              " ('hundertwasser', 0.4588957726955414),\n",
              " ('ncpa', 0.4577339291572571),\n",
              " ('maccormac', 0.4566109776496887),\n",
              " ('rothfeld', 0.4523947238922119)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función analogy() utiliza el modelo Word2Vec cargado previamente para encontrar una palabra que tenga una relación similar con y1 que la que existe entre x1 y x2. Para ello, utiliza el método most_similar() del modelo Word2Vec, que devuelve las palabras más similares a una lista de palabras dadas.\n",
        "\n",
        "Los argumentos de entrada de analogy() son tres palabras: x1, x2 y y1. En este caso, se utiliza la fórmula de analogía de palabras \"x1 es a x2 como y1 es a ___\".\n",
        "\n",
        "La función devuelve la palabra más cercana a la palabra que completa la analogía.\n",
        "\n",
        "En la fórmula de analogía de palabras \"x1 es a x2 como y1 es a ___\", x1 y x2 representan la relación que existe entre dos palabras, mientras que y1 es una palabra relacionada con x1. Por ejemplo, si x1 es \"hombre\" y x2 es \"mujer\", y1 podría ser \"rey\" y la palabra que se busca podría ser \"reina\", ya que la relación entre \"hombre\" y \"mujer\" es similar a la relación entre \"rey\" y \"reina\"."
      ],
      "metadata": {
        "id": "PAlCFYNtrw40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analogy (x1, x2, y1):\n",
        "  result =  model.most_similar(\n",
        "      positive=[y1, x2], negative = [x1]\n",
        "                               )\n",
        "  return result[0][0]"
      ],
      "metadata": {
        "id": "glCw1c9XqyJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La línea de código result = model.most_similar(positive= ['woman', 'king'], negative = ['man']) utiliza el modelo Word2Vec para realizar una operación de analogía de palabras. En este caso, se está buscando la palabra que completa la analogía \"king es a man como woman es a ___\".\n",
        "\n",
        "El método most_similar busca las palabras más similares a la lista de palabras dadas. En este caso, se busca la palabra que sea más similar a \"woman\" cuando se le resta \"man\" y se le suma \"king\", es decir, la palabra que tenga una relación similar a la que existe entre \"king\" y \"man\" pero con \"woman\".\n",
        "\n",
        "El resultado de esta operación se guarda en la variable result, que contiene una lista de tuplas con las palabras más similares y su puntuación de similitud con respecto a la operación realizada. Por ejemplo, el primer elemento de la lista sería la palabra que mejor completa la analogía."
      ],
      "metadata": {
        "id": "c5QchKm1ukJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.most_similar(positive= ['woman', 'king'], negative = ['man'])"
      ],
      "metadata": {
        "id": "7V8i5m3ft_2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(url=\"https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcR_8bEEOsiRd4sSmpPx64qZDJdV-q_nJu1eH31fLiUyIOETYCMe\")"
      ],
      "metadata": {
        "id": "nl_wuOaqtlsS",
        "outputId": "7dc04e47-b90a-4616-8323-411d9453fc27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcR_8bEEOsiRd4sSmpPx64qZDJdV-q_nJu1eH31fLiUyIOETYCMe\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' \"man\" es a \"king\" lo que \"woman\" es a :', analogy ('man', 'king', 'woman'))\n",
        "print(' \"king\" es a \"man\" lo que \"queen\" es a :', analogy ('king', 'man', 'queen'))"
      ],
      "metadata": {
        "id": "aCjkq1-Otwuq",
        "outputId": "a8d82bf2-1dd6-4de2-8aaf-f53b1da5fee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \"man\" es a \"king\" lo que \"woman\" es a : queen\n",
            " \"king\" es a \"man\" lo que \"queen\" es a : woman\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' \"colombia\" es a \"coffee\" lo que \"spain\" es a :', analogy ('colombia', 'coffee', 'spain'))\n",
        "print(' \"pen\" es a \"draw\" lo que \"camera\" es a :', analogy ('pen', 'draw', 'camera'))"
      ],
      "metadata": {
        "id": "FZWVzKN3uzl5",
        "outputId": "3ac222f6-3e03-4bef-b403-ddb500353946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \"colombia\" es a \"coffee\" lo que \"spain\" es a : wine\n",
            " \"pen\" es a \"draw\" lo que \"camera\" es a : scenes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mode.does_not_match)"
      ],
      "metadata": {
        "id": "2OS_Glqat5O-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}