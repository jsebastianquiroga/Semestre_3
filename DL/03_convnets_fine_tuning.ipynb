{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsebastianquiroga/analitica_ia_puj/blob/main/DL/03_convnets_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redes Convolucionales & Transfer Learning\n",
        "\n",
        "En este Notebook se llevará acabo el entrenamiento de un modelo de Red Neuronal utilizando Redes Convolcuionales. El objetivo principal es familiarizarse con las redes neuronales convolucionales.\n",
        "\n",
        "\n",
        "# CIFAR-10 Dataset\n",
        "\n",
        "El conjunto de datos CIFAR-10 es un conjunto de datos popular utilizado para entrenar y evaluar algoritmos de aprendizaje automático para la clasificación de imágenes. Consiste en 60,000 imágenes a color de 32x32 píxeles, divididas en 10 clases: avión, automóvil, pájaro, gato, ciervo, perro, rana, caballo, barco y camión. Hay 6,000 imágenes por clase, con 50,000 imágenes para entrenamiento y 10,000 imágenes para pruebas.\n",
        "\n",
        "\n",
        "En este ejercicio entrenaremos el mismo modelo de red neuronal en dos escenarios:\n",
        "\n",
        "1. Escenario con muchos datos\n",
        "2. Escenario con pocos datos\n",
        "\n",
        "Lo anterior nos permitirá entender la importancia de los modelos pre-entrenados (¡que veremos la siguiente sesión!)\n"
      ],
      "metadata": {
        "id": "MXzIyZFLFGfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descarga de Información\n",
        "\n",
        "Los datos de CIFAR-10 se encuentran en [`TensorFlow Datasets`](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10/load_data) y se puede acceder a ellos utilizando el método `load_data()`. "
      ],
      "metadata": {
        "id": "HuAr2KI1aTng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install visualkeras"
      ],
      "metadata": {
        "id": "Um40txXohtUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1: Building a Convolutional Neural Network from scratch using TensorFlow\n",
        "\n",
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import visualkeras\n",
        "\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "zAOBhVKM8oMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez cargada la información, procedemos a visualizar el conjunto de datos. "
      ],
      "metadata": {
        "id": "IXlW7Sw7aj9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cifar10_classes():\n",
        "    # Load the CIFAR-10 dataset\n",
        "    (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "    # Map class indices to class names\n",
        "    class_names = {\n",
        "        0: 'airplane',\n",
        "        1: 'automobile',\n",
        "        2: 'bird',\n",
        "        3: 'cat',\n",
        "        4: 'deer',\n",
        "        5: 'dog',\n",
        "        6: 'frog',\n",
        "        7: 'horse',\n",
        "        8: 'ship',\n",
        "        9: 'truck'\n",
        "    }\n",
        "\n",
        "    # Combine training images and labels for shuffling\n",
        "    data = list(zip(train_images, train_labels))\n",
        "\n",
        "    # Shuffle the data\n",
        "    np.random.shuffle(data)\n",
        "\n",
        "    # Initialize an empty array to store an image from each class\n",
        "    class_images = np.zeros((10, 32, 32, 3), dtype=np.uint8)\n",
        "\n",
        "    # Iterate over the shuffled data\n",
        "    for image, label in data:\n",
        "        if np.sum(class_images) == 10 * 32 * 32 * 3:\n",
        "            break\n",
        "\n",
        "        if np.sum(class_images[label]) == 0:\n",
        "            class_images[label] = image\n",
        "\n",
        "    # Plot an image from each class\n",
        "    fig, axs = plt.subplots(2, 5, figsize=(12, 6))\n",
        "    fig.suptitle('CIFAR-10 Classes')\n",
        "\n",
        "    for i in range(10):\n",
        "        row = i // 5\n",
        "        col = i % 5\n",
        "        ax = axs[row, col]\n",
        "        ax.imshow(class_images[i])\n",
        "        ax.set_title(class_names[i])\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to plot the CIFAR-10 classes\n"
      ],
      "metadata": {
        "id": "ZMvlaR8RUAo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_cifar10_classes()\n"
      ],
      "metadata": {
        "id": "UOT5OQ-YUrBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede apreciar que en efecto existen 10 categorías y que las imágenes son de tamaño reducido. \n",
        "\n",
        "Antes de entrenar nuestro modelo de Red Neuronal, debemos normalizar nuestros datos. Como se trata de imágenes RGB, cada canal tendrá un valor máximo de 255 (intensidad máxima de R, G o B). "
      ],
      "metadata": {
        "id": "mNUsxfV2axnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Normalice las imágenes de entrenamiento y prueba dividiendo por 255\n",
        "train_images, test_images = None, None\n",
        "###"
      ],
      "metadata": {
        "id": "K4hmIfJNVJtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos división en valdiación también\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DnsfXguzmpP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Acá no hay que modificar nada\n",
        "def plot_prediction_results(model, num_pixels = None, pre_process_fn = None, resize = None):\n",
        "    # Load the CIFAR-10 dataset\n",
        "    (_, _), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "    # Get shuffled indices for unique image selection\n",
        "    num_plots = 10\n",
        "    indices = np.arange(len(test_images))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    sampled_images = test_images[indices[:num_plots]]\n",
        "    sampled_labels = test_labels[indices[:num_plots]]\n",
        "\n",
        "    # If you want to apply transformations, make a copy of the sampled images\n",
        "    # This copy will be used for model predictions\n",
        "    transformed_images = sampled_images.copy()\n",
        "\n",
        "    if num_pixels:\n",
        "        original_shape = test_images.shape\n",
        "        transformed_images = transformed_images.reshape((num_plots,) + (num_pixels,))\n",
        "    \n",
        "    if resize:\n",
        "        transformed_images = tf.image.resize(transformed_images, resize)\n",
        "\n",
        "    # Normalize the test images\n",
        "    if pre_process_fn:\n",
        "        print('Using Pre-Trained Model Process')\n",
        "        pred_images = pre_process_fn(transformed_images)\n",
        "    else:\n",
        "        pred_images = transformed_images.astype('float32') / 255\n",
        "\n",
        "    # Get predictions from the model on the random sample\n",
        "    predictions = model.predict(pred_images)\n",
        "    predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Map class indices to class names\n",
        "    class_names = {\n",
        "        0: 'airplane',\n",
        "        1: 'automobile',\n",
        "        2: 'bird',\n",
        "        3: 'cat',\n",
        "        4: 'deer',\n",
        "        5: 'dog',\n",
        "        6: 'frog',\n",
        "        7: 'horse',\n",
        "        8: 'ship',\n",
        "        9: 'truck'\n",
        "    }\n",
        "\n",
        "    # Plot random image, predicted label, true label, and prediction probability\n",
        "    fig, axs = plt.subplots(2, 5, figsize=(12, 8))\n",
        "    fig.suptitle('Prediction Results')\n",
        "\n",
        "    for i in range(num_plots):\n",
        "        row = i // 5\n",
        "        col = i % 5\n",
        "        ax = axs[row, col]\n",
        "\n",
        "        # Select a unique test sample\n",
        "        image = sampled_images[i]\n",
        "        true_label = sampled_labels[i][0]\n",
        "        predicted_label = predicted_labels[i]\n",
        "        prediction_probability = predictions[i][predicted_label]\n",
        "\n",
        "        # Set title color based on prediction correctness\n",
        "        title_color = 'green' if predicted_label == true_label else 'red'\n",
        "\n",
        "        # Plot the image, labels, and probability\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(f'Predicted: {class_names[predicted_label]}\\nTrue: {class_names[true_label]}\\nProbability: {prediction_probability:.4f}', color=title_color)\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ZUEpkemncRC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmark -- Simple Neural Network\n",
        "\n",
        "Para evaluar la efectividad (o superioridad) de las Redes Neuronales Convolucionales, entrenaremos una red neuronal densa simple que ignora la dependencia espacial de los datos.\n",
        "\n",
        "¿Recordamos el Flattenq ue hacíamos al comienzo? Bueno, en esta sección se debe aplicar una estrategia de reshaping, bues se tienen tres canales. R, G, y B. Cada canal tiene dimensión 32*32.\n",
        "\n",
        "![Ejemplo Canales](https://i.stack.imgur.com/I4p5q.png)\n",
        "\n",
        "En este caso, se debería hacer el flatten de cada imagen y concatenar verticalmente los vectores. \n",
        "\n",
        "Vamos paso a paso.\n",
        "\n",
        "\n",
        "1. Determinar el tamaño del vector de cada canal\n",
        "2. Sumar y determinar el tamaño del vector final\n",
        "3. Hacer reshape de la imagen original en el tamaño del vector (ponerlo en una hillera)\n",
        "\n",
        "El primer paso es sencillo, pues todos los canales tienen el mismo tamaño de imagen. Basta con encontrar uno para tener el tamaño de todos los vectores."
      ],
      "metadata": {
        "id": "DOioXIUYba5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Determina el Tamaño del vector para el canal rojo\n",
        "### Pista: se calcula ancho por alto\n",
        "ancho, alto = None, None\n",
        "vector_canal = None\n",
        "###"
      ],
      "metadata": {
        "id": "RyY1tOvsjdjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez  se tiene `vector_canal` se conoce el número de pixeles que hay en total en cada canal. Por lo que el número de pixeles disponible sen la imagen es `vector_canal` multiplicado por el número de canales (en este caso, 3). "
      ],
      "metadata": {
        "id": "K_EVIv0gkHHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Encuentra el número total de pixeles informativos de la imagen\n",
        "num_pixels = None\n",
        "###"
      ],
      "metadata": {
        "id": "BS8RpyuhkVbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basado en lo anterior, ya es posible realizar un reshape de las imágenes de entrenamiento y prueba, para que puedan ser utilizadas por la red neuronal simple. Utiliza el método [`reshape`](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) para modificar el la dimensión de la imagen a un vector de tamaño `num_pixels`. "
      ],
      "metadata": {
        "id": "d2tSObvKkbkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Reshape de imágenes de tran y test (asignar nuevo nombre...)\n",
        "\n",
        "train_images_flatten =  None\n",
        "val_images_flatten =  None\n",
        "test_images_flatten =  None\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "IHUeqjT9kjN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Y ahora sí comienza lo bueno! \n",
        "\n",
        "Utilizando lo aprendido hasta el momento, crea un modelo de red neuronal densa (sencillo) para predecir la categoría de cada imagen. "
      ],
      "metadata": {
        "id": "_DuaI4wolAhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Defina la arquitectura del modelo\n",
        "\n",
        "simple_model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.InputLayer(input_shape=(num_pixels, )), # Dejarla\n",
        "  None\n",
        "\n",
        "])\n",
        "###"
      ],
      "metadata": {
        "id": "NX1V5OdNbww3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Complie el modleo\n",
        "None\n",
        "###"
      ],
      "metadata": {
        "id": "Sv3anVWmcBvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez definido y compilado el modelo, se puede realizar una visualización de la cantidad de parámetros que se van a entrenar. Utilice el método [`.summary()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#summary) para inspeccionar la arquitectura planteada."
      ],
      "metadata": {
        "id": "cUC2NqV7lYiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model.summary()"
      ],
      "metadata": {
        "id": "jIZFw6bacH1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente, utilizando la librería `visualkeras` puede entender gráficamente cómo es la red neuronal que planteó. "
      ],
      "metadata": {
        "id": "21Wb2smjl-Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualkeras.layered_view(simple_model).show()"
      ],
      "metadata": {
        "id": "ohKXdh_mh-WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez inspeccionado el modelo, entrénelo por 10 epochs (a modo de ejemplo. Pero puede utilizar muchas más si lo desea). No olvide incluir callbacks de EarlyStopping. No olvide incluir el dataset de valdiación."
      ],
      "metadata": {
        "id": "rDB9BQdTmFR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Entrene su modelo\n",
        "early_stopping = None\n",
        "\n",
        "history_simple = None\n",
        "###"
      ],
      "metadata": {
        "id": "WomEIySpcCzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Utilice el método `.evaluate` para determinar el desempeño del modelo en test \n",
        "\n",
        "test_loss, test_acc = None\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "uxytmpgDcD_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cómo le dio al modelo? ¿Es un buen modelo?"
      ],
      "metadata": {
        "id": "2YJWvxPenFq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction_results(simple_model, num_pixels)"
      ],
      "metadata": {
        "id": "DPvCIiHfgJSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Red Convolucional\n",
        "\n",
        "Una vez entrenado un modelo que ingora la información espacial que se encuentra en las imágenes, se realizará el entrenamiento de un modelo con redes neuronales convolucionales. \n",
        "\n",
        "Para esto recuerde que la arquitectura típica de una CNN es como sigue ![Arquitectura típica CNN](https://d33wubrfki0l68.cloudfront.net/a7664cf19de33b2c71a482629f27a0d70f715b77/6949d/images/blog/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way.jpg).\n",
        "\n",
        "Utilice elemenso como:\n",
        "- Convoluciones: [`Conv2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D), se sugiere kernel size `(3, 3)`. \n",
        "- Pooling Layers: [`MaxPool2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) o [`AveragePooling2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D) para el downsampling, se sugiere pool_size size `(2, 2)`.\n",
        "- [`Flatten`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)\n",
        "- [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)"
      ],
      "metadata": {
        "id": "WWsTn1dRcTQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Defina su modelo de Red Neuronal\n",
        "model = models.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(ancho, alto, 3)), # Dejarlo\n",
        "    None\n",
        "])\n",
        "\n",
        "###\n"
      ],
      "metadata": {
        "id": "3xu8Kz37GT8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Compile su modelo\n",
        "None\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "oUnzjlxwpQDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "pDgk1aLKYW2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "atgg6f1UYdlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualkeras.layered_view(model).show()"
      ],
      "metadata": {
        "id": "nc5cJwv5h4b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Y realice el entrenamiento del modelo! Nuevamente, se sugiere con 10 epochs para la clase, pero en su tiempo libre puede entrenarlo con más. "
      ],
      "metadata": {
        "id": "E1YNzZWCpU3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Entrene su modelo\n",
        "history_model = None\n",
        "\n",
        "###"
      ],
      "metadata": {
        "id": "IpC-V8ZpYYOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, revise el desempeño de su modelo en Test. ¿Qué tal el accuracy? ¿Está satisfecho?"
      ],
      "metadata": {
        "id": "5rKlKEHTpiav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction_results(model)"
      ],
      "metadata": {
        "id": "L4Sj2mjpV5zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "WwsTkZBaV8bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Transfer Learning\n",
        "\n",
        "En esta sección veremos cómo hacer Transfer Learning y Fine-Tuning de un modelo pre-entrenado con ImageNet para la generar un modelo que sí sea capaz de predecir adecuadamente estas clases.\n",
        "\n",
        "En la clase anterior vimos que existían algunos modelos famosos que habían ganado la competencia de ImageNet, como lo eran VGG16, ResNet50, GoogLeNet, entre otros. \n",
        "\n",
        "Estos modelos tienen la capacidad de reconocer muchísimas clases (22k) de objetos `naturales`. Por medio del fine-tuning, explotaremos los feature extractors de estos modelos, para llevarlo a un dominio nuevo (nuestras 10 clases). \n",
        "\n",
        "En esta demostración se utilizará como candidado [`ResNet50`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50), pero se recomienda que pruebe los otros modelos disponibles:\n",
        "\n",
        "- [`VGG16`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/VGG16)\n",
        "- [`InceptionV3`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/InceptionV3)"
      ],
      "metadata": {
        "id": "1F-pndXkX6mJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importe del Modelo\n",
        "\n",
        "A continuación, cargue el modelo que haya escogido utilizando lo smétodos descritos en la documentación. \n",
        "\n",
        "Este modelo se va a llamar `base_model` y corresponde al extractor de características. \n",
        "\n",
        "Los parámetros que debe tener en cuenta son:\n",
        "- `include_top = False`: pues no se busca predecir las mismas clases que el modelo sabe predecir\n",
        "- `weights = 'imagenet'`: Se indica que se desea cargar los pesos del modelo que predice las clases de ImageNet.\n",
        "\n",
        "\n",
        "Si va a utilizar un modelo diferente ResNet50, por favor cargue la función de pre-procesamiento requerida en `pre_process_fn`. "
      ],
      "metadata": {
        "id": "GchLUct8Zrx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Cargue el Modelo\n",
        "base_model = None\n",
        "###\n",
        "\n",
        "\n",
        "pre_process_fn = tf.keras.applications.resnet50.preprocess_input"
      ],
      "metadata": {
        "id": "dDUs2W5eYd3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalmente, se utilizan modelos muy grandes que ya fueron entrenados en un conjunto enorme de información. A continuación, se puede observar el tamaño del modelo base que se ecogió."
      ],
      "metadata": {
        "id": "Qmyvr3JdE10k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(base_model, show_shapes=True)"
      ],
      "metadata": {
        "id": "uuRiKZ-3a4dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "id": "s9WveTardR3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez realizado este procedimiento, `base_model` es un extractor de características, que se desea pasar por un nuevo modelo para predecir las 10 clases de nuestro problema. \n",
        "\n",
        "A continuación, defina el nuevo modelo: añada capas ocultas y una capa de salida:\n",
        "\n",
        "- Después de la extracción de características aplique una capa con [`GlobalAveragePooling2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D)"
      ],
      "metadata": {
        "id": "a-pME-L0amVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model.output # Corresponde a los features que extrae el modelo\n",
        "\n",
        "### Continúe la construcción del Modelo \n",
        "\n",
        "x = None # GlobalAveragePooling2D\n",
        "x = None # Añada las capas ocultas que desee\n",
        "predictions = tf.keras.layers.Dense(None, activation='softmax')(x) # Añada la capa de salida (predicción de las clases)\n",
        "\n",
        "###\n"
      ],
      "metadata": {
        "id": "tFFPOOuKYd5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, se crea el `fine_tune_model` que contiene el modelo inicial, más las capas adicionales de salida que se añadieron en la celda anterior. "
      ],
      "metadata": {
        "id": "_nxxwYP2alot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_model = tf.keras.Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "5ul5WnZmYd8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente, es importante indicar que **no se quiere dañar lo que el modelo ya sabe**, sino únicamente crear un modelo capaz de tomar ese feature extractor y crear un modelo sobre ese. Por esto, se **congelan** las capas del modelo base. "
      ],
      "metadata": {
        "id": "ERT04fjydpKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "nW_A0feLX50C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, se realiza la compilación y entrenamiento (inicial) del modelo. Utilice [`tf.keras.optimizers.Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) como optimizador con parámetro `learning_rate = 0.001`."
      ],
      "metadata": {
        "id": "labwrnq3d7xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Compile el Modelo\n",
        "fine_tune_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "              optimizer =tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "###"
      ],
      "metadata": {
        "id": "cwrfWT-gYKjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_model.summary()"
      ],
      "metadata": {
        "id": "uDb7IykojESu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para realizar el entrenamiento de este modelo, es necesario transformar los datos de forma que tengan las dimensiones esperadas (input_shape) y contengan los valores en el rango deseado por el modelo. \n",
        "\n",
        "Por ejemplo, ResNet50 utiliza imágenes de `224x224x3` y normaliza los valores entre `-1 y 1`. Los procesaimentos específicos se encuentran en `pre_process_fn`. \n",
        "\n",
        "El siguiente bloque de código transforma la información para que sea la esperada por el modelo. "
      ],
      "metadata": {
        "id": "CtnnKsnweWC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## No modificar nada (salvo new_size si cambió el modelo)\n",
        "\n",
        "# Carga nuevamente de información\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
        "# Expected Size\n",
        "new_size = (224, 224)\n",
        "\n",
        "# Convierte en TF Datasets (completo no cabe en memoria)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "\n",
        "\n",
        "\n",
        "# Transformación de Imágenes: Resize + Normalization\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, new_size)\n",
        "    image = pre_process_fn(image) \n",
        "    return image, label\n",
        "\n",
        "# Apply the function to the datasets\n",
        "train_dataset = train_dataset.map(preprocess)\n",
        "val_dataset = val_dataset.map(preprocess)\n",
        "test_dataset = test_dataset.map(preprocess)\n",
        "\n",
        "# Shuffle and batch the datasets\n",
        "BATCH_SIZE = 16\n",
        "train_dataset = train_dataset.shuffle(1000).batch(BATCH_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "ctb3DfNwjE87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history_fine_tune_model = fine_tune_model.fit(train_dataset, epochs=20,\n",
        "                    validation_data=(val_dataset),  callbacks=[early_stopping])\n",
        "\n"
      ],
      "metadata": {
        "id": "_x44sm7qecCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "jhxqt_0UiciA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction_results(fine_tune_model, pre_process_fn = pre_process_fn, resize = new_size)"
      ],
      "metadata": {
        "id": "owEdbUQ7t4Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning Even Further!\n",
        "\n",
        "En este punto, vimos claramente cómo el modelo con apenas un epoch, logra un accuracy cercano a 90% en validación y en test (vale la pena revisar las demás métricas). ¿Podemos hacer que el modelo de mucho mejor?\n",
        "\n",
        "¡Pues sí! \n",
        "\n",
        "Lo que haremos a continuación es permitir entrenar un poco más las capas finales. En la sección anterior entrenamos las capas densas que pusimos y no tocamos el extractor de características. ¿Por qué no mejoramos un poco la manera en que extraemos información?\n",
        "\n",
        "En el entrenamiento, disminuya la tasa de aprendizaje a `learning_rate = 0.0001`."
      ],
      "metadata": {
        "id": "Y1qrrpYeuQSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[143:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "### Compile el Modelo\n",
        "fine_tune_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "              optimizer =tf.keras.optimizers.Adam(learning_rate=0.0001))\n",
        "###\n",
        "\n",
        "history_fine_tune_model = fine_tune_model.fit(train_dataset, epochs=20,\n",
        "                    validation_data=(val_dataset),   callbacks=[early_stopping])\n",
        "\n"
      ],
      "metadata": {
        "id": "BVW04BuPt93S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "l3Fg3ncGu6Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding Visualization\n",
        "\n",
        "En esta sección vemos que el modelo no sólo fue capaz de clasificar adecuadamente todas las categorías. Sino que también aprendió a extraer características específicas de los grupos de CIFAR 10. "
      ],
      "metadata": {
        "id": "UcLRisFf6bA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "m6bE2sX78P1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No modificar nada\n",
        "def visualize_embeddings(model, pre_process_fn = None, num_pixels = None, resize = None):\n",
        "    from sklearn.manifold import TSNE\n",
        "    from sklearn.decomposition import PCA\n",
        "    import seaborn as sns\n",
        "\n",
        "    # Load the CIFAR-10 dataset\n",
        "     (_, _), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "    if num_pixels:\n",
        "        original_shape = test_images.shape\n",
        "        test_images = test_images.reshape((test_images.shape[0], num_pixels))\n",
        "\n",
        "    if resize:\n",
        "        test_images = tf.image.resize(test_images, resize)\n",
        "\n",
        "    # Normalize the test images\n",
        "    if pre_process_fn:\n",
        "        print('Using Pre-Trained Model Process')\n",
        "        test_images = pre_process_fn(test_images)\n",
        "    else:\n",
        "        test_images = test_images.astype('float32') / 255\n",
        "\n",
        "    # Extract embeddings from the base model\n",
        "    embeddings = model.predict(test_images)\n",
        "\n",
        "    # Flatten the embeddings\n",
        "    embeddings = embeddings.reshape(embeddings.shape[0], -1)\n",
        "\n",
        "    # Apply PCA\n",
        "    pca = PCA(n_components=60)\n",
        "    embeddings_pca = pca.fit_transform(embeddings)\n",
        "\n",
        "    # Apply t-SNE\n",
        "    tsne = TSNE(n_components=2)\n",
        "    embeddings_tsne = tsne.fit_transform(embeddings_pca)\n",
        "\n",
        "    # Create a DataFrame for easier plotting\n",
        "    df = pd.DataFrame(embeddings_tsne, columns=['comp1', 'comp2'])\n",
        "    df['labels'] = test_labels.flatten()\n",
        "\n",
        "    # Map class indices to class names\n",
        "    class_names = {\n",
        "        0: 'airplane',\n",
        "        1: 'automobile',\n",
        "        2: 'bird',\n",
        "        3: 'cat',\n",
        "        4: 'deer',\n",
        "        5: 'dog',\n",
        "        6: 'frog',\n",
        "        7: 'horse',\n",
        "        8: 'ship',\n",
        "        9: 'truck'\n",
        "    }\n",
        "    df['labels'] = df['labels'].map(class_names)\n",
        "\n",
        "    # Plot t-SNE visualization with seaborn\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    sns.scatterplot(data=df, x='comp1', y='comp2', hue='labels', palette='tab10', alpha=0.7)\n",
        "    plt.title('t-SNE Visualization of Image Embeddings')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "mhkthfei6bg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "feature_extractor = tf.keras.Model(inputs=fine_tune_model.input, outputs=fine_tune_model.get_layer('global_average_pooling2d').output)\n"
      ],
      "metadata": {
        "id": "7kRyQ-1Z6b5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_embeddings(feature_extractor, pre_process_fn=pre_process_fn)"
      ],
      "metadata": {
        "id": "4JOXlwhU7S8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "79QDCAze7n-j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}